{"cells":[{"cell_type":"markdown","id":"7fb8b01a","metadata":{"id":"7fb8b01a"},"source":["## Lab 7 :Document Clustering"]},{"cell_type":"markdown","id":"895d8a94","metadata":{"id":"895d8a94"},"source":["\n","Document clustering yet again includes similar steps, so let’s have a look at\n","them:\n","1. Tokenization\n","2. Stemming and lemmatization\n","3. Removing stop words and punctuation\n","4. Computing term frequencies or TF-IDF\n","5. Clustering: K-means/Hierarchical; we can then use\n","any of the clustering algorithms to cluster different\n","documents based on the features we have generated\n","6. Evaluation and visualization: Finally, the clustering\n","results can be visualized by plotting the clusters into\n","a two-dimensional space"]},{"cell_type":"markdown","id":"772b2ac4","metadata":{"id":"772b2ac4"},"source":["### 1)Install and import needed libraries:"]},{"cell_type":"code","execution_count":null,"id":"0d0d7c15","metadata":{"id":"0d0d7c15"},"outputs":[],"source":["#!pip install mpld3\n","#! pip install bs4\n","import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk.stem.snowball import SnowballStemmer\n","from bs4 import BeautifulSoup\n","import re\n","import os\n","import codecs # for encoding and decoding\n","from sklearn import feature_extraction\n","import mpld3  #The mpld3 project brings together Matplotlib, the popular Python-based graphing library, and D3js, the popular JavaScript library for creating interactive data visualizations for the web. The result is a simple API for exporting your matplotlib graphics to HTML code which can be used within the browser, within standard web pages, blogs, or tools such as the IPython notebook.\n","from sklearn.metrics.pairwise import cosine_similarity  \n","import os \n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from sklearn.manifold import MDS\n"]},{"cell_type":"markdown","id":"aa252379","metadata":{"id":"aa252379"},"source":["### 2)Read Data set:"]},{"cell_type":"code","execution_count":null,"id":"79884f1c","metadata":{"id":"79884f1c","outputId":"e0ad3215-84a6-4295-8336-0156201dfbfe"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Mona\\anaconda3\\envs\\tfcpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (5,11) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}],"source":["#Read Data set\n","Data = pd.read_csv(\"Consumer_Complaints.csv\",encoding='latin-1')\n","\n","#selecting required columns and rows\n","Data = Data[['consumer_complaint_narrative']]\n","Data = Data[pd.notnull(Data['consumer_complaint_narrative'])]\n","\n","# Take a sample of just 200 documents. \n","Data_sample=Data.sample(200)"]},{"cell_type":"markdown","id":"0381ac9f","metadata":{"id":"0381ac9f"},"source":["### 3)Data Preprocessing:"]},{"cell_type":"code","execution_count":null,"id":"666db8d7","metadata":{"id":"666db8d7","outputId":"46843bec-2aa8-4492-f8e1-419293d19dd8"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Mona\\anaconda3\\envs\\tfcpu\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n","  warnings.warn('Your stop_words may be inconsistent with '\n"]},{"name":"stdout","output_type":"stream","text":["(200, 29)\n"]}],"source":["Data_sample['consumer_complaint_narrative'] = Data_sample['consumer_complaint_narrative'].str.replace('XXXX','')\n","\n","# Convert dataframe to list\n","complaints = Data_sample['consumer_complaint_narrative'].tolist()\n","\n","# create the rank of documents – we will use it later\n","\n","ranks = []\n","for i in range(1, len(complaints)+1):\n","    ranks.append(i)\n","\n","# Stop Words\n","stopwords = nltk.corpus.stopwords.words('english')\n","\n","# Load 'stemmer'\n","stemmer = SnowballStemmer(\"english\")\n","\n","# Functions for sentence tokenizer, to remove numeric tokens and raw #punctuation\n","\n","def tokenize_and_stem(text):\n","    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    filtered_tokens = []\n","    for token in tokens:\n","        if re.search('[a-zA-Z]', token):\n","            filtered_tokens.append(token)\n","    stems = [stemmer.stem(t) for t in filtered_tokens]\n","    return stems\n","\n","def tokenize_only(text):\n","    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    filtered_tokens = []\n","    for token in tokens:\n","        if re.search('[a-zA-Z]', token):\n","            filtered_tokens.append(token)\n","    return filtered_tokens\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# tfidf vectorizer \n","\n","tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n","                                 min_df=0.2, stop_words='english',\n","                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n","\n","#fit the vectorizer to data\n","\n","tfidf_matrix = tfidf_vectorizer.fit_transform(complaints) \n","terms = tfidf_vectorizer.get_feature_names()\n","print(tfidf_matrix.shape)\n"]},{"cell_type":"markdown","id":"01ceab07","metadata":{"id":"01ceab07"},"source":["### 4) k-means Clustering :"]},{"cell_type":"code","execution_count":null,"id":"78a2cad7","metadata":{"id":"78a2cad7","outputId":"2bc663ec-fccc-43c7-b03f-032d52ac0e2c"},"outputs":[{"data":{"text/plain":["1    50\n","4    37\n","5    33\n","0    29\n","2    28\n","3    23\n","Name: cluster, dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Import Kmeans\n","from sklearn.cluster import KMeans\n","\n","# Define number of clusters\n","num_clusters = 6\n","\n","#Running clustering algorithm\n","km = KMeans(n_clusters=num_clusters)\n","km.fit(tfidf_matrix)\n","\n","#final clusters\n","clusters = km.labels_.tolist()\n","complaints_data = { 'rank': ranks, 'complaints': complaints, 'cluster': clusters }\n","frame = pd.DataFrame(complaints_data, index = [clusters] , columns = ['rank', 'cluster'])\n","\n","#number of docs per cluster \n","frame['cluster'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"5c6903b2","metadata":{"id":"5c6903b2","outputId":"7e89faf0-84c4-4ef3-e2e6-f26c69f1975b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cluster 0 words: b'loan', b'paying', b'because', b'company', b\"n't\", b'payments',\n","Cluster 1 words: b'reports', b'credit', b'credit', b'information', b'account', b'year',\n","Cluster 2 words: b'payments', b'month', b'told', b'paying', b'services', b'receiving',\n","Cluster 3 words: b'debt', b'account', b'company', b'credit', b'services', b'asked',\n","Cluster 4 words: b'state', b'information', b'company', b\"n't\", b'any', b'contacted',\n","Cluster 5 words: b'account', b'bank', b'day', b'credit', b'time', b'used',\n"]}],"source":["totalvocab_stemmed = []\n","totalvocab_tokenized = []\n","for i in complaints:\n","    allwords_stemmed = tokenize_and_stem(i) \n","    totalvocab_stemmed.extend(allwords_stemmed) \n","    \n","    allwords_tokenized = tokenize_only(i)\n","    totalvocab_tokenized.extend(allwords_tokenized)\n","\n","vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n","\n","#sort cluster centers by proximity to centroid\n","order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n","\n","for i in range(num_clusters):\n","    print(\"Cluster %d words:\" % i, end='')\n","    \n","    for ind in order_centroids[i, :6]: \n","        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n","    print()"]},{"cell_type":"markdown","id":"64b4bbb8","metadata":{"id":"64b4bbb8"},"source":["### 5) Data Visualization:"]},{"cell_type":"code","execution_count":null,"id":"bcf21b8b","metadata":{"id":"bcf21b8b"},"outputs":[],"source":["#Similarity\n","\n","similarity_distance = 1 - cosine_similarity(tfidf_matrix)\n","\n","\n","# Convert two components as we're plotting points in a two-dimensional plane\n","mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n","pos = mds.fit_transform(similarity_distance)  # shape (n_components, n_samples)\n","xs, ys = pos[:, 0], pos[:, 1]\n","\n","#Set up colors per clusters using a dict\n","cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e',5: '#D2691E'}\n","\n","#set up cluster names using a dict\n","cluster_names = {0: 'property, based, assist', \n","                 1: 'business, card', \n","                 2: 'authorized, approved, believe', \n","                 3: 'agreement, application,business', \n","                 4: 'closed, applied, additional',\n","                 5: 'applied, card'}\n","\n","# Finally plot it\n","%matplotlib inline \n","\n","#Create data frame that has the result of the MDS and the cluster \n","df = pd.DataFrame(dict(x=xs, y=ys, label=clusters)) \n","groups = df.groupby('label')\n","\n","# Set up plot\n","fig, ax = plt.subplots(figsize=(17, 9)) # set size\n","\n","for name, group in groups:\n","    ax.plot(group.x, group.y, marker='o', linestyle='', ms=20, \n","            label=cluster_names[name], color=cluster_colors[name], \n","            mec='none')\n","    ax.set_aspect('auto')\n","    ax.tick_params(\\\n","        axis= 'x',          \n","        which='both',      \n","        bottom='off',     \n","        top='off',         \n","        labelbottom='off')\n","    ax.tick_params(\\\n","        axis= 'y',        \n","        which='both',    \n","        left='off',     \n","        top='off',       \n","        labelleft='off')\n","    \n","ax.legend(numpoints=1) \n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"820c7bca","metadata":{"id":"820c7bca"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}